{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 169,
   "metadata": {},
   "outputs": [],
   "source": [
    "%matplotlib inline\n",
    "\n",
    "import pandas            as pd\n",
    "import seaborn           as sns\n",
    "import matplotlib.pyplot as plt\n",
    "import nltk\n",
    "\n",
    "from sklearn.model_selection         import train_test_split\n",
    "from sklearn.linear_model            import LogisticRegression\n",
    "from sklearn.feature_extraction.text import CountVectorizer\n",
    "from wordcloud                       import WordCloud\n",
    "from nltk                            import tokenize\n",
    "from string                          import punctuation\n",
    "#Criando variável com os dados de teste.\n",
    "data = pd.read_csv(\"C:/Users/lucas/Documents/GitHub/NLTK_IA/imdb-reviews-pt-br.csv\")\n",
    "\n",
    "#Criando as variáveis com as informações segregadas.\n",
    "treino, teste, class_treino, class_teste = train_test_split(data.text_pt, data.sentiment, random_state = 42)\n",
    "\n",
    "#trocando as informações da coluna, para os valores legiveis pela IA.\n",
    "classificacao = data[\"sentiment\"].replace([\"neg\", \"pos\"], [0, 1])\n",
    "\n",
    "data[\"classificacao\"] = classificacao\n",
    "\n",
    "#Define que a variável palavras receba toda a base de dados a serem usados.\n",
    "palavras = ''.join([texto for texto in data.text_pt])\n",
    "\n",
    "#Possibilita seprar as palavras, a partir de espaçoes em branco.\n",
    "token_espaco    = tokenize.WhitespaceTokenizer()\n",
    "token_pontuacao = tokenize.WordPunctTokenizer()\n",
    "\n",
    "#Cria uma lista de palavras indesejadas\n",
    "palavras_irrelevantes = nltk.corpus.stopwords.words(\"portuguese\")\n",
    "\n",
    "#Cria uma lista de pontuações.\n",
    "pontuacao = list()\n",
    "for ponto in punctuation:\n",
    "    pontuacao.append(ponto)\n",
    "    \n",
    "palavrasi_pontuacaoi = pontuacao + palavras_irrelevantes\n",
    "\n",
    "#Classificação das palavras, primeira apuração de precisão da IA.\n",
    "#Compara os textos e retorna uma acurácia\n",
    "def class_texto(texto, coluna_texto, coluna_classificacao):\n",
    "    vetorizar = CountVectorizer(lowercase=False, max_features=50)\n",
    "    bag_of_words = vetorizar.fit_transform(texto[coluna_texto])\n",
    "    treino, teste, class_treino, class_teste = train_test_split(bag_of_words,\n",
    "                                                                texto[coluna_classificacao],\n",
    "                                                                random_state = 42)\n",
    "\n",
    "    #Absorção de toda a base de dados use: LogisticRegression(max_iter=1000)\n",
    "    reg_log = LogisticRegression()\n",
    "    reg_log.fit(treino, class_treino)\n",
    "    return reg_log.score(teste, class_teste)\n",
    "\n",
    "#Retorna a imagem da WordCloud baseana das opiniões negativas.\n",
    "def palavras_neg(texto_neg, coluna_texto):\n",
    "    texto_neg = data.query(\"sentiment == 'neg'\")\n",
    "    palavras = ''.join([texto for texto in texto_neg[coluna_texto]])\n",
    "\n",
    "    nuvem_palavras = WordCloud(width = 1100, height = 550, \n",
    "                                max_font_size = 110,\n",
    "                                collocations = False).generate(palavras)\n",
    "    \n",
    "    #Configuração da umagem a ser exibida\n",
    "    plt.figure(figsize=(15,10))\n",
    "    plt.imshow(nuvem_palavras, interpolation = 'bilinear')\n",
    "    plt.axis('off')\n",
    "    plt.show()\n",
    "\n",
    "#Retorna a imagem da WordCloud baseana das opiniões positivas.\n",
    "def palavras_pos(texto_pos, coluna_texto):\n",
    "    texto_pos = data.query(\"sentiment == 'pos'\")\n",
    "    palavras = ''.join([texto for texto in texto_pos[coluna_texto]])\n",
    "\n",
    "    nuvem_palavras = WordCloud(width = 1100, height = 550, \n",
    "                                max_font_size = 110,\n",
    "                                collocations = False).generate(palavras)\n",
    "    \n",
    "    #Configuração da umagem a ser exibida\n",
    "    plt.figure(figsize=(15,10))\n",
    "    plt.imshow(nuvem_palavras, interpolation = 'bilinear')\n",
    "    plt.axis('off')\n",
    "    plt.show()\n",
    "\n",
    "#Retorna a imagem da WordCloud baseana em todas as opiniões.\n",
    "def palavras_geral(texto_pos, coluna_texto):\n",
    "    palavras = ''.join([texto for texto in data.text_pt])\n",
    "\n",
    "    #Criação da \"Nuvem de palavras\", que representa de forma concentrada as palavras mais repetidas.\n",
    "    nuvem_palavras = WordCloud(width = 1100, height = 550, \n",
    "                                max_font_size = 110,\n",
    "                                collocations = False).generate(palavras)\n",
    "    \n",
    "    #Configuração da umagem a ser exibida\n",
    "    plt.figure(figsize=(15,10))\n",
    "    plt.imshow(nuvem_palavras, interpolation = 'bilinear')\n",
    "    plt.axis('off')\n",
    "    plt.show()\n",
    "\n",
    "#Produz um gráfico que indica a quantidaede de vezes que uma palavra foi repetida.\n",
    "def pareto (texto, coluna_texto, quantidade):\n",
    "    palavras = ' '.join([texto for texto in texto[coluna_texto]])\n",
    "    #Aplica o token criando anteriormente para todas as palavras\n",
    "    token_frase = token_espaco.tokenize(palavras)\n",
    "    #Cria uma frequencia para todas as lapavras, individualemnte\n",
    "    frequencia = nltk.FreqDist(token_frase)\n",
    "    #Inicia uma visualização para cada uma dessas palavras, de acordo com sua uantidade de aparições\n",
    "    df_frequencia = pd.DataFrame({\"Palavra\": list(frequencia.keys()),\"Frequencia\": list(frequencia.values())})\n",
    "    #Limita para quantidade X de linhas\n",
    "    maisVistas = df_frequencia.nlargest(columns = \"Frequencia\", n = quantidade)\n",
    "    #Configuração da umagem a ser exibida\n",
    "    plt.figure(figsize=(15,10))\n",
    "\n",
    "    ax = sns.barplot(data = maisVistas, x = \"Palavra\", y = \"Frequencia\", color = 'gray')\n",
    "    ax.set(ylabel = 'Contagem')\n",
    "    plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 170,
   "metadata": {},
   "outputs": [],
   "source": [
    "#palavras_neg(data, \"text_pt\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 171,
   "metadata": {},
   "outputs": [],
   "source": [
    "#palavras_pos(data, \"text_pt\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 172,
   "metadata": {},
   "outputs": [],
   "source": [
    "#palavras(data, \"text_pt\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 173,
   "metadata": {},
   "outputs": [],
   "source": [
    "#int('Acurácia de: ',class_texto(data, \"text_pt\", \"classificacao\"),', a partir de: 63398966 palavras')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 174,
   "metadata": {},
   "outputs": [],
   "source": [
    "#class_texto(data, \"text_pt\", \"classificacao\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 175,
   "metadata": {},
   "outputs": [],
   "source": [
    "#pareto(data, \"text_pt\", 10)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 181,
   "metadata": {},
   "outputs": [],
   "source": [
    "#Trata as palavras, de acordo com aquilo que deve se removido e adiciona uma nova coluna com as informações tratadas.\n",
    "def tratarEspacos(palavras, palavras_indesejadas, nova_coluna):\n",
    "    frase_processada = list()\n",
    "    for opiniao in palavras:\n",
    "        nova_frase = list()\n",
    "        palavras_opiniao = token_espaco.tokenize(opiniao)\n",
    "        for palavra in palavras_opiniao:\n",
    "            if palavra not in palavras_indesejadas:\n",
    "                nova_frase.append(palavra)\n",
    "        frase_processada.append(' '.join(nova_frase))\n",
    "    data[nova_coluna] = frase_processada\n",
    "    \n",
    "def tratarPontuacao(palavras, palavras_indesejadas, nova_coluna):\n",
    "    frase_processada = list()\n",
    "    for opiniao in palavras:\n",
    "        nova_frase = list()\n",
    "        palavras_opiniao = token_pontuacao.tokenize(opiniao)\n",
    "        for palavra in palavras_opiniao:\n",
    "            if palavra not in palavras_indesejadas:\n",
    "                nova_frase.append(palavra)\n",
    "        frase_processada.append(' '.join(nova_frase))\n",
    "    data[nova_coluna] = frase_processada"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 182,
   "metadata": {},
   "outputs": [],
   "source": [
    "#data_Updated = tratar(data.text_pt, palavras_irrelevantes, \"tratamento_1\")\n",
    "\n",
    "#data.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 183,
   "metadata": {},
   "outputs": [],
   "source": [
    "#class_texto(data, \"tratamento_1\", \"classificacao\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 184,
   "metadata": {},
   "outputs": [],
   "source": [
    "#pareto(data, \"tratamento_1\", 10)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 185,
   "metadata": {},
   "outputs": [],
   "source": [
    "data_Updated = tratarEspacos(data.text_pt, palavras_irrelevantes, \"tratamento_1\")\n",
    "data_Updated = tratarPontuacao(data.tratamento_1, palavrasi_pontuacaoi, \"tratamento_2\")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 186,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>id</th>\n",
       "      <th>text_en</th>\n",
       "      <th>text_pt</th>\n",
       "      <th>sentiment</th>\n",
       "      <th>classificacao</th>\n",
       "      <th>tratamento_1</th>\n",
       "      <th>tratamento_2</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>1</td>\n",
       "      <td>Once again Mr. Costner has dragged out a movie...</td>\n",
       "      <td>Mais uma vez, o Sr. Costner arrumou um filme p...</td>\n",
       "      <td>neg</td>\n",
       "      <td>0</td>\n",
       "      <td>Mais vez, Sr. Costner arrumou filme tempo nece...</td>\n",
       "      <td>Mais vez Sr Costner arrumou filme tempo necess...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>2</td>\n",
       "      <td>This is an example of why the majority of acti...</td>\n",
       "      <td>Este é um exemplo do motivo pelo qual a maiori...</td>\n",
       "      <td>neg</td>\n",
       "      <td>0</td>\n",
       "      <td>Este exemplo motivo maioria filmes ação mesmos...</td>\n",
       "      <td>Este exemplo motivo maioria filmes ação mesmos...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>3</td>\n",
       "      <td>First of all I hate those moronic rappers, who...</td>\n",
       "      <td>Primeiro de tudo eu odeio esses raps imbecis, ...</td>\n",
       "      <td>neg</td>\n",
       "      <td>0</td>\n",
       "      <td>Primeiro tudo odeio raps imbecis, poderiam agi...</td>\n",
       "      <td>Primeiro tudo odeio raps imbecis poderiam agir...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>4</td>\n",
       "      <td>Not even the Beatles could write songs everyon...</td>\n",
       "      <td>Nem mesmo os Beatles puderam escrever músicas ...</td>\n",
       "      <td>neg</td>\n",
       "      <td>0</td>\n",
       "      <td>Nem Beatles puderam escrever músicas todos gos...</td>\n",
       "      <td>Nem Beatles puderam escrever músicas todos gos...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>5</td>\n",
       "      <td>Brass pictures movies is not a fitting word fo...</td>\n",
       "      <td>Filmes de fotos de latão não é uma palavra apr...</td>\n",
       "      <td>neg</td>\n",
       "      <td>0</td>\n",
       "      <td>Filmes fotos latão palavra apropriada eles, ve...</td>\n",
       "      <td>Filmes fotos latão palavra apropriada verdade ...</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "   id                                            text_en  \\\n",
       "0   1  Once again Mr. Costner has dragged out a movie...   \n",
       "1   2  This is an example of why the majority of acti...   \n",
       "2   3  First of all I hate those moronic rappers, who...   \n",
       "3   4  Not even the Beatles could write songs everyon...   \n",
       "4   5  Brass pictures movies is not a fitting word fo...   \n",
       "\n",
       "                                             text_pt sentiment  classificacao  \\\n",
       "0  Mais uma vez, o Sr. Costner arrumou um filme p...       neg              0   \n",
       "1  Este é um exemplo do motivo pelo qual a maiori...       neg              0   \n",
       "2  Primeiro de tudo eu odeio esses raps imbecis, ...       neg              0   \n",
       "3  Nem mesmo os Beatles puderam escrever músicas ...       neg              0   \n",
       "4  Filmes de fotos de latão não é uma palavra apr...       neg              0   \n",
       "\n",
       "                                        tratamento_1  \\\n",
       "0  Mais vez, Sr. Costner arrumou filme tempo nece...   \n",
       "1  Este exemplo motivo maioria filmes ação mesmos...   \n",
       "2  Primeiro tudo odeio raps imbecis, poderiam agi...   \n",
       "3  Nem Beatles puderam escrever músicas todos gos...   \n",
       "4  Filmes fotos latão palavra apropriada eles, ve...   \n",
       "\n",
       "                                        tratamento_2  \n",
       "0  Mais vez Sr Costner arrumou filme tempo necess...  \n",
       "1  Este exemplo motivo maioria filmes ação mesmos...  \n",
       "2  Primeiro tudo odeio raps imbecis poderiam agir...  \n",
       "3  Nem Beatles puderam escrever músicas todos gos...  \n",
       "4  Filmes fotos latão palavra apropriada verdade ...  "
      ]
     },
     "execution_count": 186,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "data.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.5"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
